{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch \n",
    "from stable_baselines3 import PPO, DQN\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.env import MultiODEnv, SparseMultiODEnv\n",
    "from src.problem import MultiODProblem\n",
    "from src.utils import read_instance_data\n",
    "from src.rl.stable_baselines3.nn import PSExtractor\n",
    "from src.rl.stable_baselines3.callback import SaveBestSolCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_dir = os.path.join('data', 'tsppdlib', 'instances', 'random-uniform')\n",
    "instances = [i for i in os.listdir(instance_dir) if i.endswith('.tsp')]\n",
    "num_Os = [\"005\", \"010\", \"020\", \"050\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_cost(instance):\n",
    "    target = re.search(r\"random-\\d+-\\d+\", instance).group()\n",
    "    target_cost_dir = os.path.join('data', 'U')\n",
    "    files = [file for file in os.listdir(target_cost_dir) if file.endswith('.tour')]\n",
    "    found_file = next(file for file in files if target in file)\n",
    "    target_cost = int(re.search(r\"\\.(.*?)\\.\", found_file).group(1))\n",
    "    return target_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_drl_experiment(instance):\n",
    "    episode_max_time_length = int(1e3)\n",
    "    episode_max_length = int(2e4)\n",
    "    n_steps = episode_max_length\n",
    "    learn_total_steps = int(2e3) * episode_max_length\n",
    "    verbose = 1\n",
    "    batch_size = 1000\n",
    "    tensorboard_log = '../tmp/ppo'\n",
    "    callback_log_dir = '../tmp/paths'\n",
    "    \n",
    "    target_cost = get_target_cost(instance)\n",
    "    locations = read_instance_data(instance)\n",
    "    problem = MultiODProblem(locations=locations, ignore_to_dummy_cost=False)\n",
    "    env = MultiODEnv(problem=problem, max_length=episode_max_length, max_time_length=episode_max_time_length)\n",
    "    \n",
    "    features_dim = env.observation_space['solution'].shape[-1] + env.observation_space['problem'].shape[0]\n",
    "    hidden_dim = 64\n",
    "    num_heads = 4\n",
    "    lr = 0.001\n",
    "    \n",
    "    policy_kwargs = dict(\n",
    "        features_extractor_class=PSExtractor,\n",
    "        features_extractor_kwargs=dict(features_dim=features_dim, \n",
    "                                       sol_input_dim=env.observation_space['solution'].shape[-1],\n",
    "                                       hidden_dim=hidden_dim,\n",
    "                                       num_heads=num_heads),\n",
    "        net_arch=dict(pi=[64, 64], vf=[64, 64])\n",
    "    )\n",
    "    model = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=verbose, n_steps=n_steps, batch_size=batch_size, learning_rate=lr, tensorboard_log=tensorboard_log)\n",
    "    # model = DQN(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=verbose, train_freq=n_steps, batch_size=batch_size, tensorboard_log=tensorboard_log)\n",
    "    \n",
    "    instance_save_as = re.search(r\"random-\\d+-\\d+\", instance).group()\n",
    "    model.learn(learn_total_steps, \n",
    "                tb_log_name=instance_save_as,\n",
    "                callback=SaveBestSolCallback(log_dir=callback_log_dir, \n",
    "                                         instance_name=instance_save_as, \n",
    "                                         verbose=verbose,\n",
    "                                         target_cost=target_cost)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing num-005:   0%|                                | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ../tmp/ppo/random-005-03942_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution cost: 5833.852399508786, found at 1 step, 0.00 seconds used\n",
      "Best solution cost: 5319.505335000748, found at 3 step, 0.01 seconds used\n",
      "Best solution cost: 4701.673969203509, found at 6 step, 0.01 seconds used\n",
      "Best solution cost: 3755.511978843458, found at 10 step, 0.02 seconds used\n",
      "Best solution cost: 3633.374948569405, found at 19 step, 0.02 seconds used\n",
      "Best solution cost: 3599.6670062438134, found at 80 step, 0.06 seconds used\n",
      "Rollout best solution cost: 3599.6670062438134, \n",
      "                  found at 80 step, \n",
      "                  0.06 seconds used. \n",
      "\n",
      "                  Convergence gap: 3599.6670062438134. Target gap: 0.6670062438133755\n",
      "---------------------------------------------\n",
      "| best/                          |          |\n",
      "|    best_cost                   | 3.6e+03  |\n",
      "|    best_sol_at_step            | 80       |\n",
      "|    best_sol_found_time         | 0.0608   |\n",
      "| rollout/                       |          |\n",
      "|    convergence_gap             | 3.6e+03  |\n",
      "|    ep_len_mean                 | 2e+04    |\n",
      "|    ep_rew_mean                 | 1.52e+06 |\n",
      "|    rollout_best_cost           | 3.6e+03  |\n",
      "|    rollout_best_sol_at_step    | 80       |\n",
      "|    rollout_best_sol_found_time | 0.0624   |\n",
      "|    target_gap                  | 0.667    |\n",
      "| time/                          |          |\n",
      "|    fps                         | 1908     |\n",
      "|    iterations                  | 1        |\n",
      "|    time_elapsed                | 10       |\n",
      "|    total_timesteps             | 20000    |\n",
      "---------------------------------------------\n",
      "Rollout best solution cost: 3599.6670062438134, \n",
      "                  found at 393 step, \n",
      "                  0.21 seconds used. \n",
      "\n",
      "                  Convergence gap: 0.0. Target gap: 0.6670062438133755\n",
      "-------------------------------------------------\n",
      "| rollout/                       |              |\n",
      "|    convergence_gap             | 0            |\n",
      "|    ep_len_mean                 | 2e+04        |\n",
      "|    ep_rew_mean                 | 1.58e+06     |\n",
      "|    rollout_best_cost           | 3.6e+03      |\n",
      "|    rollout_best_sol_at_step    | 393          |\n",
      "|    rollout_best_sol_found_time | 0.215        |\n",
      "|    target_gap                  | 0.667        |\n",
      "| time/                          |              |\n",
      "|    fps                         | 549          |\n",
      "|    iterations                  | 2            |\n",
      "|    time_elapsed                | 72           |\n",
      "|    total_timesteps             | 40000        |\n",
      "| train/                         |              |\n",
      "|    approx_kl                   | 0.0032617492 |\n",
      "|    clip_fraction               | 0.0084       |\n",
      "|    clip_range                  | 0.2          |\n",
      "|    entropy_loss                | -3.04        |\n",
      "|    explained_variance          | 0.000143     |\n",
      "|    learning_rate               | 0.001        |\n",
      "|    loss                        | 1.28e+06     |\n",
      "|    n_updates                   | 10           |\n",
      "|    policy_gradient_loss        | -0.00542     |\n",
      "|    value_loss                  | 2.57e+06     |\n",
      "-------------------------------------------------\n",
      "Rollout best solution cost: 3599.6670062438134, \n",
      "                  found at 175 step, \n",
      "                  0.10 seconds used. \n",
      "\n",
      "                  Convergence gap: 0.0. Target gap: 0.6670062438133755\n",
      "-------------------------------------------------\n",
      "| rollout/                       |              |\n",
      "|    convergence_gap             | 0            |\n",
      "|    ep_len_mean                 | 2e+04        |\n",
      "|    ep_rew_mean                 | 1.65e+06     |\n",
      "|    rollout_best_cost           | 3.6e+03      |\n",
      "|    rollout_best_sol_at_step    | 175          |\n",
      "|    rollout_best_sol_found_time | 0.0971       |\n",
      "|    target_gap                  | 0.667        |\n",
      "| time/                          |              |\n",
      "|    fps                         | 452          |\n",
      "|    iterations                  | 3            |\n",
      "|    time_elapsed                | 132          |\n",
      "|    total_timesteps             | 60000        |\n",
      "| train/                         |              |\n",
      "|    approx_kl                   | 0.0026008517 |\n",
      "|    clip_fraction               | 0.0033       |\n",
      "|    clip_range                  | 0.2          |\n",
      "|    entropy_loss                | -3.04        |\n",
      "|    explained_variance          | 6.44e-05     |\n",
      "|    learning_rate               | 0.001        |\n",
      "|    loss                        | 1.5e+06      |\n",
      "|    n_updates                   | 20           |\n",
      "|    policy_gradient_loss        | -0.00405     |\n",
      "|    value_loss                  | 2.89e+06     |\n",
      "-------------------------------------------------\n",
      "Rollout best solution cost: 3599.6670062438134, \n",
      "                  found at 80 step, \n",
      "                  0.05 seconds used. \n",
      "\n",
      "                  Convergence gap: 0.0. Target gap: 0.6670062438133755\n",
      "------------------------------------------------\n",
      "| rollout/                       |             |\n",
      "|    convergence_gap             | 0           |\n",
      "|    ep_len_mean                 | 2e+04       |\n",
      "|    ep_rew_mean                 | 1.71e+06    |\n",
      "|    rollout_best_cost           | 3.6e+03     |\n",
      "|    rollout_best_sol_at_step    | 80          |\n",
      "|    rollout_best_sol_found_time | 0.046       |\n",
      "|    target_gap                  | 0.667       |\n",
      "| time/                          |             |\n",
      "|    fps                         | 416         |\n",
      "|    iterations                  | 4           |\n",
      "|    time_elapsed                | 192         |\n",
      "|    total_timesteps             | 80000       |\n",
      "| train/                         |             |\n",
      "|    approx_kl                   | 0.002637521 |\n",
      "|    clip_fraction               | 0.00135     |\n",
      "|    clip_range                  | 0.2         |\n",
      "|    entropy_loss                | -3.03       |\n",
      "|    explained_variance          | -4.48e-05   |\n",
      "|    learning_rate               | 0.001       |\n",
      "|    loss                        | 1.56e+06    |\n",
      "|    n_updates                   | 30          |\n",
      "|    policy_gradient_loss        | -0.00364    |\n",
      "|    value_loss                  | 3.27e+06    |\n",
      "------------------------------------------------\n",
      "Rollout best solution cost: 3599.6670062438134, \n",
      "                  found at 109 step, \n",
      "                  0.06 seconds used. \n",
      "\n",
      "                  Convergence gap: 0.0. Target gap: 0.6670062438133755\n",
      "-------------------------------------------------\n",
      "| rollout/                       |              |\n",
      "|    convergence_gap             | 0            |\n",
      "|    ep_len_mean                 | 2e+04        |\n",
      "|    ep_rew_mean                 | 1.8e+06      |\n",
      "|    rollout_best_cost           | 3.6e+03      |\n",
      "|    rollout_best_sol_at_step    | 109          |\n",
      "|    rollout_best_sol_found_time | 0.0604       |\n",
      "|    target_gap                  | 0.667        |\n",
      "| time/                          |              |\n",
      "|    fps                         | 397          |\n",
      "|    iterations                  | 5            |\n",
      "|    time_elapsed                | 251          |\n",
      "|    total_timesteps             | 100000       |\n",
      "| train/                         |              |\n",
      "|    approx_kl                   | 0.0028022104 |\n",
      "|    clip_fraction               | 0.00954      |\n",
      "|    clip_range                  | 0.2          |\n",
      "|    entropy_loss                | -3.01        |\n",
      "|    explained_variance          | 3.04e-05     |\n",
      "|    learning_rate               | 0.001        |\n",
      "|    loss                        | 1.83e+06     |\n",
      "|    n_updates                   | 40           |\n",
      "|    policy_gradient_loss        | -0.00432     |\n",
      "|    value_loss                  | 3.6e+06      |\n",
      "-------------------------------------------------\n",
      "Rollout best solution cost: 3599.6670062438134, \n",
      "                  found at 86 step, \n",
      "                  0.05 seconds used. \n",
      "\n",
      "                  Convergence gap: 0.0. Target gap: 0.6670062438133755\n",
      "-------------------------------------------------\n",
      "| rollout/                       |              |\n",
      "|    convergence_gap             | 0            |\n",
      "|    ep_len_mean                 | 2e+04        |\n",
      "|    ep_rew_mean                 | 1.9e+06      |\n",
      "|    rollout_best_cost           | 3.6e+03      |\n",
      "|    rollout_best_sol_at_step    | 86           |\n",
      "|    rollout_best_sol_found_time | 0.05         |\n",
      "|    target_gap                  | 0.667        |\n",
      "| time/                          |              |\n",
      "|    fps                         | 385          |\n",
      "|    iterations                  | 6            |\n",
      "|    time_elapsed                | 311          |\n",
      "|    total_timesteps             | 120000       |\n",
      "| train/                         |              |\n",
      "|    approx_kl                   | 0.0047227545 |\n",
      "|    clip_fraction               | 0.0192       |\n",
      "|    clip_range                  | 0.2          |\n",
      "|    entropy_loss                | -2.98        |\n",
      "|    explained_variance          | -4.05e-06    |\n",
      "|    learning_rate               | 0.001        |\n",
      "|    loss                        | 2.35e+06     |\n",
      "|    n_updates                   | 50           |\n",
      "|    policy_gradient_loss        | -0.00553     |\n",
      "|    value_loss                  | 4.45e+06     |\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout best solution cost: 3599.6670062438134, \n",
      "                  found at 593 step, \n",
      "                  0.31 seconds used. \n",
      "\n",
      "                  Convergence gap: 0.0. Target gap: 0.6670062438133755\n",
      "-------------------------------------------------\n",
      "| rollout/                       |              |\n",
      "|    convergence_gap             | 0            |\n",
      "|    ep_len_mean                 | 2e+04        |\n",
      "|    ep_rew_mean                 | 2.01e+06     |\n",
      "|    rollout_best_cost           | 3.6e+03      |\n",
      "|    rollout_best_sol_at_step    | 593          |\n",
      "|    rollout_best_sol_found_time | 0.312        |\n",
      "|    target_gap                  | 0.667        |\n",
      "| time/                          |              |\n",
      "|    fps                         | 377          |\n",
      "|    iterations                  | 7            |\n",
      "|    time_elapsed                | 370          |\n",
      "|    total_timesteps             | 140000       |\n",
      "| train/                         |              |\n",
      "|    approx_kl                   | 0.0046183593 |\n",
      "|    clip_fraction               | 0.0152       |\n",
      "|    clip_range                  | 0.2          |\n",
      "|    entropy_loss                | -2.94        |\n",
      "|    explained_variance          | 1.61e-05     |\n",
      "|    learning_rate               | 0.001        |\n",
      "|    loss                        | 2.51e+06     |\n",
      "|    n_updates                   | 60           |\n",
      "|    policy_gradient_loss        | -0.00642     |\n",
      "|    value_loss                  | 5.4e+06      |\n",
      "-------------------------------------------------\n",
      "Rollout best solution cost: 3599.6670062438134, \n",
      "                  found at 12 step, \n",
      "                  0.01 seconds used. \n",
      "\n",
      "                  Convergence gap: 0.0. Target gap: 0.6670062438133755\n",
      "------------------------------------------------\n",
      "| rollout/                       |             |\n",
      "|    convergence_gap             | 0           |\n",
      "|    ep_len_mean                 | 2e+04       |\n",
      "|    ep_rew_mean                 | 2.14e+06    |\n",
      "|    rollout_best_cost           | 3.6e+03     |\n",
      "|    rollout_best_sol_at_step    | 12          |\n",
      "|    rollout_best_sol_found_time | 0.00773     |\n",
      "|    target_gap                  | 0.667       |\n",
      "| time/                          |             |\n",
      "|    fps                         | 371         |\n",
      "|    iterations                  | 8           |\n",
      "|    time_elapsed                | 430         |\n",
      "|    total_timesteps             | 160000      |\n",
      "| train/                         |             |\n",
      "|    approx_kl                   | 0.004964881 |\n",
      "|    clip_fraction               | 0.0226      |\n",
      "|    clip_range                  | 0.2         |\n",
      "|    entropy_loss                | -2.89       |\n",
      "|    explained_variance          | 6.79e-06    |\n",
      "|    learning_rate               | 0.001       |\n",
      "|    loss                        | 3.38e+06    |\n",
      "|    n_updates                   | 70          |\n",
      "|    policy_gradient_loss        | -0.00637    |\n",
      "|    value_loss                  | 6.43e+06    |\n",
      "------------------------------------------------\n",
      "Rollout best solution cost: 3599.6670062438134, \n",
      "                  found at 170 step, \n",
      "                  0.09 seconds used. \n",
      "\n",
      "                  Convergence gap: 0.0. Target gap: 0.6670062438133755\n",
      "-------------------------------------------------\n",
      "| rollout/                       |              |\n",
      "|    convergence_gap             | 0            |\n",
      "|    ep_len_mean                 | 2e+04        |\n",
      "|    ep_rew_mean                 | 2.28e+06     |\n",
      "|    rollout_best_cost           | 3.6e+03      |\n",
      "|    rollout_best_sol_at_step    | 170          |\n",
      "|    rollout_best_sol_found_time | 0.0939       |\n",
      "|    target_gap                  | 0.667        |\n",
      "| time/                          |              |\n",
      "|    fps                         | 366          |\n",
      "|    iterations                  | 9            |\n",
      "|    time_elapsed                | 491          |\n",
      "|    total_timesteps             | 180000       |\n",
      "| train/                         |              |\n",
      "|    approx_kl                   | 0.0064322525 |\n",
      "|    clip_fraction               | 0.0151       |\n",
      "|    clip_range                  | 0.2          |\n",
      "|    entropy_loss                | -2.81        |\n",
      "|    explained_variance          | 4.31e-05     |\n",
      "|    learning_rate               | 0.001        |\n",
      "|    loss                        | 4.02e+06     |\n",
      "|    n_updates                   | 80           |\n",
      "|    policy_gradient_loss        | -0.00707     |\n",
      "|    value_loss                  | 8.12e+06     |\n",
      "-------------------------------------------------\n",
      "Rollout best solution cost: 3599.6670062438134, \n",
      "                  found at 55 step, \n",
      "                  0.03 seconds used. \n",
      "\n",
      "                  Convergence gap: 0.0. Target gap: 0.6670062438133755\n",
      "------------------------------------------------\n",
      "| rollout/                       |             |\n",
      "|    convergence_gap             | 0           |\n",
      "|    ep_len_mean                 | 2e+04       |\n",
      "|    ep_rew_mean                 | 2.44e+06    |\n",
      "|    rollout_best_cost           | 3.6e+03     |\n",
      "|    rollout_best_sol_at_step    | 55          |\n",
      "|    rollout_best_sol_found_time | 0.0318      |\n",
      "|    target_gap                  | 0.667       |\n",
      "| time/                          |             |\n",
      "|    fps                         | 362         |\n",
      "|    iterations                  | 10          |\n",
      "|    time_elapsed                | 551         |\n",
      "|    total_timesteps             | 200000      |\n",
      "| train/                         |             |\n",
      "|    approx_kl                   | 0.008312421 |\n",
      "|    clip_fraction               | 0.0168      |\n",
      "|    clip_range                  | 0.2         |\n",
      "|    entropy_loss                | -2.72       |\n",
      "|    explained_variance          | 8.77e-05    |\n",
      "|    learning_rate               | 0.001       |\n",
      "|    loss                        | 4.6e+06     |\n",
      "|    n_updates                   | 90          |\n",
      "|    policy_gradient_loss        | -0.00814    |\n",
      "|    value_loss                  | 9.42e+06    |\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing num-005:   0%|                                | 0/25 [09:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m selected_file \u001b[38;5;129;01min\u001b[39;00m tqdm(selected_files, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing num-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m     instance \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(instance_dir, selected_file)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mrun_drl_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m, in \u001b[0;36mrun_drl_experiment\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# model = DQN(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=verbose, train_freq=n_steps, batch_size=batch_size, tensorboard_log=tensorboard_log)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m instance_save_as \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\"\u001b[39m, instance)\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[0;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn_total_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_save_as\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSaveBestSolCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_log_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43minstance_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_save_as\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mtarget_cost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_cost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m           \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:281\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime/total_timesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps, exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdump(step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps)\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:210\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_sde:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mreset_noise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m--> 210\u001b[0m values, log_prob, entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Normalize advantage\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/policies.py:692\u001b[0m, in \u001b[0;36mActorCriticPolicy.evaluate_actions\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03mEvaluate actions according to the current policy,\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;124;03mgiven the observations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m    and entropy of the action distribution.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;66;03m# Preprocess the observation if needed\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[1;32m    694\u001b[0m     latent_pi, latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor(features)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/policies.py:640\u001b[0m, in \u001b[0;36mActorCriticPolicy.extract_features\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m:param obs: Observation\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m:return: the output of the features extractor(s)\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    642\u001b[0m     pi_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mextract_features(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi_features_extractor)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/policies.py:131\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m :return: The extracted features\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m preprocessed_obs \u001b[38;5;241m=\u001b[39m preprocess_obs(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, normalize_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_images)\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_obs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Files/Columbia/Research/LAHR/src/rl/stable_baselines3/nn.py:31\u001b[0m, in \u001b[0;36mPSExtractor.forward\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m     29\u001b[0m solution_features, problem_features \u001b[38;5;241m=\u001b[39m observations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m'\u001b[39m], observations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     30\u001b[0m solution_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(solution_features, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m sol_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msol_embed_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m sol_embed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(sol_embed, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     33\u001b[0m sol_embed, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msol_self_attn(sol_embed, sol_embed, sol_embed)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/miniconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for num in num_Os:\n",
    "    pattern = re.compile(\".*-\" + num + \"-.*\")\n",
    "    selected_files = [file_name for file_name in instances if re.match(pattern, file_name)]\n",
    "    for selected_file in tqdm(selected_files, desc=f\"Processing num-{num}\"):\n",
    "        instance = os.path.join(instance_dir, selected_file)\n",
    "        run_drl_experiment(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
